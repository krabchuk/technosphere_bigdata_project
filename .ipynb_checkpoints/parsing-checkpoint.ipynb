{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "# получаем ссылки на все страницы\n",
    "def get_total_pages(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    last_page_html = soup.find_all('a', class_='pagination-page')[-1].get('href')\n",
    "    num_last_page = last_page_html.split('=')[1].split('&')[0]\n",
    "    \n",
    "    all_urls = ['https://www.avito.ru' + last_page_html.split('=')[0] + '=' \\\n",
    "                + str(i) + '&radius=0&f=188_893b0&i=1' \\\n",
    "                for i in range(1, int(num_last_page))]\n",
    "    return all_urls\n",
    "    \n",
    "# получаем все ссылки на обхъявления с одной страницы\n",
    "def get_page_urls(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    sp_ads = soup.find_all('a', class_='item-description-title-link')\n",
    "    ads = [i.get('href') for i in sp_ads]\n",
    "    urls = ['https://www.avito.ru' + str(i) for i in ads]\n",
    "    return urls\n",
    "\n",
    "# получаем данные одного объявления\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    params_html = soup.find('div', class_='item-params').find_all('li', class_='item-params-list-item')\n",
    "    \n",
    "    params = [i.text.strip() for i in params_html]\n",
    "    price_html = soup.find('span', class_='js-item-price')\n",
    "    price = 'Цена: ' + price_html.text.strip()\n",
    "    params.append(price)\n",
    "    return params\n",
    "\n",
    "# получаем все даныне об объявлениях одной страниы\n",
    "def get_all_page_params(html):\n",
    "    urls = get_page_urls(html)\n",
    "    parameters = []\n",
    "    for url in urls:\n",
    "        html = get_html(url)\n",
    "        param = get_page_data(html)\n",
    "        parameters.append(param)\n",
    "    return parameters\n",
    "\n",
    "# надо вставить url 2ой страницы из авито\n",
    "# получаем массив из строк для всех страниц всех обхявлений\n",
    "def get_all_data(url):\n",
    "    html_for_total_pages = get_html(url)\n",
    "    total_pages_urls = get_total_pages(html_for_total_pages)\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for page_url in total_pages_urls:\n",
    "        page_html = get_html(page_url)\n",
    "        adds_urls = get_page_urls(page_html)\n",
    "        \n",
    "        page_data = []\n",
    "        sleep(3)\n",
    "        for ad_url in adds_urls:\n",
    "            ad_html = get_html(ad_url)\n",
    "            sleep(1)\n",
    "            one_data = get_page_data(ad_html)\n",
    "            url_of_data = 'Ссылка: ' + ad_url\n",
    "            one_data.append(url_of_data)\n",
    "            one_data.append(ad_url)\n",
    "            page_data.append(one_data)\n",
    "            sleep(1)\n",
    "        all_data.extend(page_data)\n",
    "        \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем из массива массивов строк dataframe\n",
    "def get_pd_data(data):\n",
    "    df = pd.DataFrame(index=np.arange(len(data)),\n",
    "                      columns=['Марка', 'Модель', 'Год выпуска', 'Тип кузова',\n",
    "                               'Цена', 'Объём двигателя', 'Цвет', 'Привод',\n",
    "                               'Руль', 'Тип двигателя', 'Состояние', 'Владельцев по ПТС',\n",
    "                               'Количество дверей', 'Мощность двигателя', 'Пробег',\n",
    "                               'VIN или номер кузова', 'Коробка передач', 'Ссылка'])\n",
    "    for j in range(len(data)):\n",
    "        for i in range(len(data[j])):\n",
    "            tmp = data[j][i].split(': ')\n",
    "            df.loc[j][tmp[0]] = tmp[1]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8972ce7ca193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.avito.ru/moskva/avtomobili/subaru?p=2&radius=0&i=1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist_of_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-5f406a0c071a>\u001b[0m in \u001b[0;36mget_all_data\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mad_url\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madds_urls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mad_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mone_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_page_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0murl_of_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Ссылка: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mad_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mone_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_of_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5f406a0c071a>\u001b[0m in \u001b[0;36mget_page_data\u001b[0;34m(html)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_page_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mparams_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item-params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'li'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item-params-list-item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams_html\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# парсим весь раздел с субарами(для теста)\n",
    "url = 'https://www.avito.ru/moskva/avtomobili/subaru?p=2&radius=0&i=1'\n",
    "list_of_data = get_all_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_pd_data(list_of_data)\n",
    "df.to_csv('subaru.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
